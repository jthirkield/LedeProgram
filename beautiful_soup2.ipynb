{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This brings us to Beautiful Soup\n",
    "Beautiful Soup is a Python library that parses HTML, allowing us to navigate through the elements of a webpage using the HTML tags embedded in it. [Here is the link to the documentation,](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) there are examples and Extensions Beyond what is demonstrated below.\n",
    "\n",
    "Now it's time to install Beautiful soup. Go to your terminal/shell/bash and type:\n",
    "\n",
    "`pip3 install bs4`\n",
    "\n",
    "We will begin by navigating a very simple HTML page I have posted on my website. [Please follow this link](http://floatingmedia.com/columbia/topfivelists.html) and try inspecting the HTML using Chrome. (p.s. The information on this page comes from [http://www.boxofficemojo.com/genres/chart/?id=comicbookadaptation.htm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below uses the built in URL Library to import the file from the web. `raw_html` holds the text of that file.\n",
    "\n",
    "In the following cell, printing raw_html gives us all the text that was in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "raw_html = urlopen(\"http://floatingmedia.com/columbia/topfivelists.html\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(type(raw_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(raw_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we import Beautiful soup and create a new variable called soup_doc. In that variable we transform the text that we downloaded from the URL (the text in raw_html) into a beautiful soup object that we can investigate with built in functions (like .find())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup_doc = BeautifulSoup(raw_html, \"html.parser\")\n",
    "print(type(soup_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(soup_doc.prettify())\n",
    "#print(soup_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a very simple example of beautiful soup's built in functions. .title is shorthand for .find('title'). It finds the first title tag in the document. If we append .string we get the text inside the tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup_doc.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup_doc.title.string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are first getting comfortable with beautiful soup, it is wise to use the .find() notation. find() searches for the first instance of a tag, and returns the contents of the tag as well as its tags. (Remember .string strips away the tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup_doc.find('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Most often when we are scraping HTML simply finding one tag will not do the trick. We need to navigate hierarchically down the tree of nested tags. We'll begin by searching the first list that is contained in the first `<div>` tag. Since we are looking for the first occurrence, we can use .find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup_doc.find('div')\n",
    "#soup_doc.div  # would also work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we navigate the tree: starting at the outer `<div>` tag, and then we use find_all() to get every `<p>` tag nested inside. After that we loop through the `<p>` tags, and pull out the text that is inside the `<b>` tag, using `string` get us just the name of the movies with no tags around it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_div = soup_doc.find('div')\n",
    "#first_div Is a variable that contains all HTML in the first div \n",
    "all_paragraphs = first_div.find_all('p')\n",
    "#.find_all() gives us a list\n",
    "#so to search elements inside that list \n",
    "#we now need to loop through it\n",
    "for movies in all_paragraphs:\n",
    "    print(movies.find('b').string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More on find_all()**\n",
    "\n",
    "If there are more than one of the same tags, find_all() gives us a list. We can use list notation to get a specific element in the list. The first cell below gives us a list of every single `<p>` tag in the document. In the following cell, we get a list of all of the `<p>` tags inside the first `<div>`. Try changing the index number `[0]` for each of these lists to see what you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup_doc.find_all('p')[0]\n",
    "# uncomment the line below to see the full list\n",
    "#soup_doc.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup_doc.find('div').find_all('p')[0]\n",
    "#soup_doc.find('div').find_all('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a one line search down the tree. Note that I specify the index number of the `<p>` tag I want to search further. Again, if I wanted to search all of the `<p>` tags, I would need to use a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup_doc.find('div').find_all('p')[2].find('b').string\n",
    "#soup_doc.div.find_all('p')[2].b.string ##Same thing but shorter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are two examples of searching the first list and pulling it out the name and date of the third movie in the list [2] -- try changing that index number to get movies in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "that_movie = soup_doc.find('div').find_all('p')[2]\n",
    "movie_name = that_movie.find('b')\n",
    "movie_year = that_movie.find('span')\n",
    "print(movie_name, movie_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "that_movie = soup_doc.find('div').find_all('p')[2]\n",
    "movie_name = that_movie.b\n",
    "movie_year = that_movie.find('span')\n",
    "print(movie_name.string, \"||\", movie_year.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get the next list (the second `<div>` or list element [1]) and then pull out all of the names and dates by using a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "next_list = soup_doc.find_all('div')[1]\n",
    "print(next_list)\n",
    "next_movies = next_list.find_all('p')\n",
    "print(next_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for movie in next_movies:\n",
    "    movie_name = movie.b\n",
    "    movie_year = movie.find('span')\n",
    "    print(movie_name.string, \"||\", movie_year.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the third list, we could have gotten `<div>` [2], but because it has a unique `<ul>` parent tag--we go straight for that.\n",
    "\n",
    "Try this: get 'Ghost in the Shell' out of that list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#third_list = soup_doc.find_all('div')[2].find('li')\n",
    "third_list = soup_doc.find_all('ul')\n",
    "print(third_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parents, children, and siblings**\n",
    "\n",
    "So far we have navigated the DOM tree from parent to child-- div > p > b\n",
    "\n",
    "Sometimes you want to go the opposite direction, find a unique identifier inside a container and then get everything in the container. For example, as we saw the third list has a unique `<ul>` tag. If he wanted to get everything that is inside the same parent container (the `<div>`) we could do something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup_doc.find('ul').parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also go sideways, meaning finding siblings--elements that are in the same container at the same level of the hierarchy. As you've seen, the fourth list is not in its own div. To get the fourth list we could use the unique `<h2>` to get all of the siblings that come after it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_head = soup_doc.find('h2')\n",
    "last_list = last_head.find_next_siblings()\n",
    "last_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even specify what kind siblings you want to find--notice how that's final \"that's all\" showed up. We can search for all of the next `<p>` tags. (There is also a previous_siblings function goes backwards.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_head = soup_doc.find('h2')\n",
    "last_list = last_head.find_next_siblings('p')\n",
    "last_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Searching id and class**\n",
    "\n",
    "Most websites these days use id and class attributes to style (and run code) on their webpages. These can be some of the most helpful attributes to search for to find certain types/groups of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Finds all classes named \"year\"\n",
    "all_years = soup_doc.find_all(class_=\"year\")\n",
    "print(all_years)\n",
    "#Try printing out just the years without any tags around them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Finds any tag that has an id attribute in it\n",
    "fav = soup_doc.find_all(id=True)\n",
    "print(fav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fav = soup_doc.find_all(id='favorite')\n",
    "print(fav)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also search for any kind of attribute beyond id and class, and you can specify what kind of tag you want to look for that attribute in. This is very helpful for zoning in on specific parts of the webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fav = soup_doc.find_all('p', attrs={'id': 'favorite'})\n",
    "print(fav)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Pulling out attributes**\n",
    "\n",
    "Not only can you search by attributes but you can pull out the information hidden inside a tag. The most common information you will want to get is a link. Like in this tag: \n",
    "`<a href=\"http://www.boxofficemojo.com/movies/?id=avengers11.htm\">more info</a>`\n",
    "\n",
    "URLs are found in `<a>` tags inside the `href` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_link = soup_doc.find('a')\n",
    "get_url = first_link['href']\n",
    "print(get_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using that link!**\n",
    "\n",
    "Here I am taking a real link to box office mojo and scraping a table with some basic information about the movie--and turning that info into a dictionary! I will cover this in class on Thursday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_html2 = urlopen(get_url).read()\n",
    "soup_doc2 = BeautifulSoup(raw_html2, \"html.parser\")\n",
    "print(soup_doc2.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_table = soup_doc2.find(\"table\", attrs={\"bgcolor\": \"#dcdcdc\"})\n",
    "print(my_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "each_entry = my_table.find_all('td')\n",
    "each_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(each_entry[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for entry in each_entry:\n",
    "    the_data = entry.find('b')\n",
    "    the_category = the_data.previous_sibling\n",
    "    print(the_data.string)\n",
    "    print(the_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avengers_dict = {}\n",
    "for entry in each_entry:\n",
    "    the_data = entry.find('b')\n",
    "    the_category = the_data.previous_sibling\n",
    "    data_string = the_data.string\n",
    "    the_category = the_category[:-2].replace(' ','')\n",
    "    avengers_dict[the_category] = data_string\n",
    "avengers_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avengers_dict['Genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
